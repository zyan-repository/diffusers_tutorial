{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5f499ec",
   "metadata": {},
   "source": [
    "# CLIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790ba857",
   "metadata": {},
   "source": [
    "![clip](../images/CLIP.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594add81",
   "metadata": {},
   "source": [
    "## 1 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40482dbc",
   "metadata": {},
   "source": [
    "### 1.1 结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741ae857",
   "metadata": {},
   "source": [
    "![clip_pretrain](../images/clip_pretrain.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17888a0",
   "metadata": {},
   "source": [
    "什么是CLIP？  \n",
    "CLIP的英文全称是Contrastive Language-Image Pre-training，即一种基于对比文本-图像对的预训练方法（模型）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac21de01",
   "metadata": {},
   "source": [
    "[什么是对比学习？](https://ankeshanand.com/blog/2020/01/26/contrative-self-supervised-learning.html)  \n",
    "自监督学习（一种机器学习范式，模型自行从无标注数据学习）当前被分为两类：  \n",
    "1、Generative Methods（生成式方法）  \n",
    "2、Contrastive Methods（对比式方法）  \n",
    "Generative Methods（生成式方法）这类方法以自编码器为代表，主要关注像素级损失。扩散模型是典型的生成式自监督模型（回忆DDPM原理，预测噪声的MSE损失函数是不是“像素级”的）。  \n",
    "生成式方法的缺点：  \n",
    "（1）使用像素级的损失可能导致模型更关心像素级的细节而忽略（图片中）更抽象的潜在因子。  \n",
    "（2）基于像素的目标通常假设像素间的独立性，从而降低了它们对相关性或复杂结构建模的能力。  \n",
    "\n",
    "Contrastive Methods（对比式方法）这类方法则是通过将数据分别与正例样本和负例样本在特征空间进行对比，来学习样本的特征表示。因此对比学习不会过分关注像素细节，而能够关注抽象的语义信息，并且相比于像素级别的重构，优化也变得更加简单。对比学习主要的难点在于如何构造正负样本。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11280956",
   "metadata": {},
   "source": [
    "对比式方法是如何工作的？  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d09a880",
   "metadata": {},
   "source": [
    "### 1.2 伪代码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5840acdf",
   "metadata": {},
   "source": [
    "![clip_numpylike_pseudocode](../images/clip_numpylike_pseudocode.jpg)  \n",
    "参数解释：  \n",
    "image encoder： 图像编码器。作用是提前图像特征，可以使用任意模型（论文中的例子给的resnet和视觉transformer）\n",
    "text encoder： 文本编码器，也是扩散模型中使用的部分。作用是提取文本特征，同样可以使用任意模型（论文中的例子给的resnet和文本transformer）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55edb43c",
   "metadata": {},
   "source": [
    "## 2 zero-shot分类处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84fda64",
   "metadata": {},
   "source": [
    "![clip_cls_zero_shot](../images/clip_cls_zero_shot.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be21c13",
   "metadata": {},
   "source": [
    "## 3 相关资料\n",
    "论文： [Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/pdf/2103.00020.pdf)  \n",
    "[openai官方仓库](https://github.com/openai/CLIP)   \n",
    "[b站讲解](https://www.bilibili.com/video/BV1SL4y1s7LQ/?buvid=4672c179b3e1ee9116c2b795f3d3061a&is_story_h5=false&mid=8JJ%2Fot%2BaDbPrUImwdIrMww%3D%3D&p=1&plat_id=116&share_from=ugc&share_medium=iphone&share_plat=ios&share_session_id=8CD31657-D253-413A-9758-A395C26332EE&share_source=WEIXIN&share_tag=s_i&timestamp=1693463757&unique_k=rIhhRL2&up_id=1567748478)  \n",
    "[open clip](https://github.com/mlfoundations/open_clip)： 一个CLIP开源框架，可以训练自己的CLIP，同时提供比官方模型效果更好的第三方预训练模型。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
